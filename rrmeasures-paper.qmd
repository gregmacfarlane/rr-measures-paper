---
title: |
  Towards Accelerating Transportation Research:  Measuring the Practice of Open Science 
#subtitle: 
author:
  - name: Junyi Ji
  - name: Ruth Lu
  - name: Yongqin Dong
  - name: Liming Wang
  - name: Bahman Madadi
  - name: Silvia Varotto
  - name: Nicolas Saunier
  - name: Gregory S. Macfarlane
    affiliations: 
        - id: byuce
          name: Brigham Young University
          department: Civil and Construction Engineering
  - name: Mostafa Ameli
  - name: Cathy Wu
    email: cathywu@mit.edu
    affiliations:
        - id: mit 
          name: Massachusetts Institute of Technology
          department: Civil and Environmental Engineering
    attributes:
        corresponding: true
abstract: |
  This is the abstract. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum augue turpis, dictum non malesuada a, volutpat eget velit. Nam placerat turpis purus, eu tristique ex tincidunt et. Mauris sed augue eget turpis ultrices tincidunt. Sed et mi in leo porta egestas. Aliquam non laoreet velit. Nunc quis ex vitae eros aliquet auctor nec ac libero. Duis laoreet sapien eu mi luctus, in bibendum leo molestie. Sed hendrerit diam diam, ac dapibus nisl volutpat vitae. Aliquam bibendum varius libero, eu efficitur justo rutrum at. Sed at tempus elit.
keywords: 
  - Open Science
  - Large Language Models
date: last-modified
bibliography: main.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: |
        Transportation Research Part C: Emerging Technologies
      formatting: review
      model: 3p # Don't set a model with preprint
      cite-style: authoryear
    # commands to render comments from authors
    include-in-header: 
      text: |
        \usepackage{xcolor}
        \newcommand{\cw}[1]{\textcolor{orange}{#1}}
        \newcommand{\Junyi}[1]{\textcolor{purple}{#1}}
        \newcommand{\Ruth}[1]{\textcolor{teal}{#1}}
        \newcommand{\Greg}[1]{\textcolor{blue}{#1}}
        \newcommand{\Yongqi}[1]{\textcolor{violet}{#1}}
        \newcommand{\Linda}[1]{\textcolor{pink}{#1}}
        \renewcommand\thefootnote{\textcolor{orange}{\arabic{footnote}}}
        \newcommand{\cwfn}[1]{\footnote{\textcolor{orange}{CW: #1}}}
        \newcommand{\Junyifn}[1]{\footnote{\textcolor{purple}{Junyi: #1}}}
        \usepackage{setspace}
        \AtBeginEnvironment{tblr}{\begin{singlespacing}}
        \AtEndEnvironment{tblr}{\end{singlespacing}}
---

```{r setup, include=FALSE, cache=FALSE}
library(tidyverse) # various data manipulation tools
library(rstatix) # tidy statistical tests
library(modelsummary) # summary tables
library(tinytable)
library(kableExtra)

knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=" ")
})


```

# Introduction {#intro}
I need a citation to keep from getting a latex error, so @nosek2015promoting is a good one.

# Analysis

## Descriptive statistics and bivariate tests

```{r papers, echo=FALSE, message=FALSE, warning=FALSE}
papers <- read_csv("data/10k_final/papers_cleaned_with_new_columns.csv") |>
    # Filter out papers that don't need to be included because they are not quantitative studies
    filter(is_quantitative_study) |>
    filter(!is.na(is_data_repository_available)) |> # remove papers that have a missing data repository information
    mutate(
      # Make some labels that will look better in tables
      # also, combine some of the variables into a multi-variable
      is_open_access = ifelse(open_access == TRUE, 'Open access', 'Not open access'),
      citations_per_year = citation_count/paper_age_years,
      acceptance_date_ld = lubridate::as_date(acceptance_date),
      date = ifelse(
        is.na(acceptance_date_ld), 
        lubridate::as_date(str_c(year, "-06-01", sep = "")),
        acceptance_date_ld),
      data_multi = case_when(
        is_data_repository_available == TRUE & is_data_cited_or_linked == TRUE ~ 'Data repository and citation',
        is_data_repository_available == TRUE ~ 'Data repository is available',
        is_data_cited_or_linked == TRUE ~ 'Data is cited or linked',
        TRUE ~ 'No repository or citation'
      ),
      data_multi3 = case_when(
        is_data_repository_available == TRUE ~ 'Data repository',
        is_data_cited_or_linked == TRUE ~ 'Data cited only',
        TRUE ~ 'No repository or citation'
      ),
      is_data_repository_available = ifelse(is_data_repository_available == TRUE, 
        'Data repository is available', 'Data repository is not available'),
      is_code_available = ifelse(is_code_publicly_available == TRUE, 
        'Code is available', 'Code is not available'),
      # bitbucket and gitlab combine for just a handful of repos, so we'll do github, other, and none
      code_links = case_when(
        has_code_link_github ~ 'Link to GitHub',
        n_code_links > 0 ~ 'Link to other service',
        TRUE ~ 'No links'
      ),
      is_simulation_study = ifelse(is_simulation_study == TRUE, 'Simulation study', 'Not a simulation study'),
      is_data_cited_or_linked = ifelse(is_data_cited_or_linked == TRUE, 
        'Data is cited or linked', 'Data is not cited or linked'),
      availability_statement_present = ifelse(availability_statement_present == TRUE, 
        'Availability statement is present', 'Availability statement is not present'),
    ) 

n_open <- papers |>
  filter(is_open_access == 'Open access') |>
  nrow()

n_code <- papers |>
  filter(is_code_available == 'Code is available') |>
  nrow()
n_data <- papers |> group_by(data_multi) |> tally() |> mutate(pct = round(n/sum(n)*100, 0)) 
```

The analysis dataset contains `r nrow(papers)` papers, processed from all full-length
articles that were identified as `is_quantitative_study` papers). 
@tbl-descriptives shows descriptive statistics for the dataset, including
organized by whether the papers made code available. The dataset contains `r n_open` 
papers with code available, about `r round(n_code/nrow(papers)*100, 0)`% of the papers.
In total, about `r n_data$pct[1]`% of the papers cite publicly available data, but only
`r n_data$pct[2] + n_data$pct[3]`% of the papers include a data repository; the remaining `r n_data$pct[4]`% 
neither cite data nor include a repository.


```{r echo=FALSE}
#| label: tbl-descriptives
#| tbl-cap: Descriptive Statistics of Data Set
ds <- papers |>
  mutate(journal = str_remove(journal, "Transportation Research ")) |>
  select(
    `Open Access` = is_open_access,  
    `Open science score` = open_science_score_0_5, 
    `Age of paper [years]` = paper_age_years, 
    `N. tables in paper` = table_number, 
    `N. figures in paper` = figure_number, 
    `N. references` = reference_count, 
    `N. authors` = num_authors,
    `Times cited` = citation_count, 
    `Review time [days]` = review_time_days,
    `Page count` = page_count,
    `Data availability` = data_multi, 
    is_code_available, 
    `Journal` = journal, 
    `Region of corr. author` = region_normalized, 
    `Availability statement` = availability_statement_present, 
    `Paper topic` = lda_topic, 
    `Links to code repositories` = code_links, 
  )
    
datasummary_balance(~ is_code_available,
  data = ds, dinm = FALSE, 
  width = c(2, 3.5, 1, 1, 1, 1), output = "kableExtra") |>
  row_spec(c(10, 12, 16, 23, 29, 31, 46), extra_latex_after = "\\midrule") |>
  kable_styling(latex_options="scale_down")
```



```{r bivariates, include=FALSE}
chi2_data_code <- chisq.test(papers$is_code_publicly_available, papers$data_multi)
t_code_years <- papers |> t_test(paper_age_years ~ is_code_publicly_available, detailed = TRUE) |> arrange(group2)
t_data_years <- papers |> t_test(paper_age_years ~ data_multi, detailed = TRUE) |> arrange(group2)
```

We conducted a series of initial bivariate statistical tests on the dependent
variables --- specifically, whether the papers provide code or data --- using
$t$-tests on differences of means when the independent variable is numeric, and
Pearson $\chi^2$ tests of independence when the independent variable is
categorical. The results of these tests revealed several statistically
significant relationships that guided the analysis that follows below.
To begin, papers that make code available are also more likely to share data 
($\chi^2$ test statistic of `r round(chi2_data_code$statistic, 2)`).
Newer papers make code available more frequently 
($t$-test `r round(t_code_years$statistic[1], 2)`), and papers that share data directly 
tend to be newer than papers simply citing existing data
($t$-test between data repository
and links `r round(abs(t_data_years$statistic[1]),2)` ) Papers with
corresponding authors in Europe and North America are more likely to make data
available than papers with authors in Asia; the same trend holds for sharing
code, with South American authors joining the group more likely to share than
Asian authors. In absolute terms, authors based in Asia still contribute a
substantial number ($N=118$) of code repositories, but their share appears lower
when expressed as a percentage of the total number of publications from the
region ($N=4516$). 

These findings are informative, but they may be the result of correlated omitted variables.
In a section below we provide a choice model of data and code availability that
can accommodate the simultaneous influence of multiple variables.
Additionally, the analyses assume that the data is accurate, which the above agreement analysis
indicated is not entirely true.  

## Incentives for availability

```{r include=FALSE}
papers |> 
  filter(data_multi == "Data repository and citation") |>
  group_by(year) |>
  arrange(desc(citations_per_year)) |>
  select(year, journal, lda_topic, citations_per_year) |>
  slice(1:5)
```

For researchers to take the extra effort to publish their data or their analysis
code, there need to be incentives to do so. These incentives may be captured by
a higher rate of citations or a reduced review time prior to publication.
Unfortunately, neither incentive is observable in the papers we studied.
@fig-citations-1 shows the citations per year for each paper
organized by paper acceptance date in SCOPUS and data availability, and
@fig-citations-2 the same information by code availability. In neither case are
the average citation rates different based on the availability of data or code.
The average citation rate for papers that provided both a data repository and a
citation to existing data was elevated in 2020 and 2021; this effect was
primarily driven by two heavily-cited papers accepted in 2020 that shared data
and a citation to existing data. The overall citation rate for papers sharing
both a data repository and a citation to existing data has returned to a similar
rate as the rate for papers that do not share data in the intervening years.

```{r echo=FALSE}
review_time_data <- papers |> t_test(review_time_days ~ data_multi, detailed = TRUE) |> arrange(group2)
review_time_code <- papers |> t_test(review_time_days ~ is_code_available, detailed = TRUE) |> arrange(group2)
```

In terms of review time, there was no difference in mean time for papers based
on data sharing practice. There was, however, a statistically meaningful
*increase* in the time to review papers that shared code repositories
based on a $t$-test of the difference in mean review time. We observed a 95\%
confidence interval between `r round(review_time_code$conf.low[1])` and 
`r round(review_time_code$conf.high[1])` days longer for papers with a code
repository than papers that did not share a code repository based on a $t$-test
of the difference in mean review time.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#| label: fig-citations
#| dev: tikz
#| sanitize: TRUE
#| standAlone: FALSE
#| fig-cap: Citations per year of each paper over time by code and data-sharing practice, with a LOESS moving average line applied for mean comparison.
#| fig-subcap: 
#|   - Citations per year by data sharing practice.
#|   - Citations per year by code sharing practice.
# wesanderson::wes_palette("Asteroid1") 
pal <- c("#0A9F9D", "#E54E21", "#6C8645", "#CEB175")
ggplot(papers, aes(x = acceptance_date_ld, y = citations_per_year + 1, color = data_multi, fill = data_multi)) +
  geom_bin2d(bins = 100, alpha = 0.2) +
  #geom_point(alpha = 0.2, raster = TRUE)+ 
  geom_smooth(method = "loess") + 
  # facet_wrap(~ data_multi) +
  scale_y_log10() + theme_bw() + ylab("Citations per Year") + xlab("Acceptance Date") + 
  scale_x_date() + 
  scale_color_discrete(name = "Data sharing practice", palette = pal) + 
  scale_fill_discrete(name = "Data sharing practice", palette = pal)  

pal <- c("#0A9F9D",  "#CEB175")
ggplot(papers, aes(x = acceptance_date_ld, y = citations_per_year + 1, color = is_code_available, fill = is_code_available)) +
  geom_bin2d(bins = 100, alpha = 0.2) +
  geom_smooth(method = "loess") + 
  # facet_wrap(~ data_multi) +
  scale_y_log10() + theme_bw() + ylab("Citations per Year") + xlab("Acceptance Date") + 
  scale_x_date() + 
  scale_color_discrete(name = "Code sharing practice", palette = pal) + 
  scale_fill_discrete(name = "Code sharing practice", palette = pal) 
```

## Temporal, topic, and journal trends of data and code availability

@fig-temporal-trends shows the temporal trend of data availability by journal in @fig-temporal-trends-1, and 
the temporal trend of code availability by journal in @fig-temporal-trends-2. As to data availability, there
is a slight positive trend in the percent of papers that include a data repository, but there is a somewhat negative trend
in the percent of papers using cited data.  

```{r echo=FALSE, warning=FALSE, message=FALSE}
#| label: fig-temporal-trends
#| dev: tikz
#| fig-cap: Temporal trends of data and code availability.
#| fig-subcap: 
#|   - Data availability by journal over time.
#|   - Code availability by journal over time.
# wesanderson::wes_palette("Zissou1") 
pal <- c("#3A9AB2", "#85B7B9", "#ADC397", "#DCCB4E", "#E5A208", "#ED6E04", "#F11B00")
papers |>
  mutate(journal = str_remove(journal, "Transportation Research ")) |>
  group_by(year, journal, data_multi3) |>
  summarise(n = n()) |> 
  mutate(pct = n/sum(n))  |>
  filter(data_multi3 != "No repository or citation")  |>
ggplot(aes(x = year, y = pct, color = journal)) + 
  geom_line() + 
  facet_wrap(~ data_multi3) + theme_bw() + 
  scale_y_continuous("Percent of papers", labels = function(x) sprintf("%.0f\\%%", 100 * x)) + 
  scale_x_continuous("Publication year") + 
  scale_color_manual(name = "Journal", values = pal) + 
  theme_bw() + theme(legend.position = "none")

papers |>
  mutate(journal = str_remove(journal, "Transportation Research ")) |>
  group_by(year, journal, is_code_available) |>
  summarise(n = n()) |> 
  group_by(year, journal) |>
  mutate(pct = n/sum(n))  |>
  filter(is_code_available == "Code is available")  |>
ggplot(aes(x = year, y = pct, color = journal)) + 
  geom_line()  + 
  scale_y_continuous("Percent of papers sharing code", labels = function(x) sprintf("%.0f\\%%", 100 * x)) + 
  scale_x_continuous("Publication year") + 
  scale_color_manual(name = "Journal", values = pal) + 
  theme_bw()
```
